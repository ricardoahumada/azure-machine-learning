{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01b4662",
   "metadata": {},
   "source": [
    "# **Ciclo de Vida de Creación y Entrenamiento de Modelos en Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812edf5",
   "metadata": {},
   "source": [
    "\n",
    "### **1. Ingesta de Datos (1 hora)**\n",
    "\n",
    "#### **1.1. Enfoque de Azure ML para la Ingesta de Datos**\n",
    "Azure Machine Learning ofrece múltiples opciones para la ingesta de datos, permitiendo integrar datos desde diversas fuentes externas. Estas opciones están diseñadas para ser escalables, seguras y fáciles de usar.\n",
    "\n",
    "- **Azure Blob Storage:**  \n",
    "  - Ideal para almacenar grandes volúmenes de datos no estructurados.\n",
    "  - Proporciona conectores nativos para acceder a archivos como CSV, JSON, imágenes, etc.\n",
    "  - Soporta autenticación mediante claves de acceso o tokens SAS (Shared Access Signature).\n",
    "\n",
    "- **Bases de Datos SQL:**  \n",
    "  - Permite conectar bases de datos SQL Server, PostgreSQL o MySQL utilizando drivers como `pyodbc` o `SQLAlchemy`.\n",
    "\n",
    "- **APIs RESTful:**  \n",
    "  - Integración con APIs externas para obtener datos en tiempo real.\n",
    "\n",
    "- **Azure Data Lake Storage (ADLS):**  \n",
    "  - Una alternativa más avanzada que Blob Storage, optimizada para análisis de big data.\n",
    "\n",
    "- **Conjuntos de Datos Registrados en Azure ML:**  \n",
    "  - Azure ML permite registrar conjuntos de datos (`Dataset`) para facilitar su reutilización en pipelines.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure Blob Storage Documentation](https://learn.microsoft.com/en-us/azure/storage/blobs/)\n",
    "- [Azure Data Lake Storage Documentation](https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction)\n",
    "- [Azure ML Datasets Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-register-datasets)\n",
    "\n",
    "#### **1.2. Opciones y Posibilidades**\n",
    "- **Autenticación Segura:**  \n",
    "  - Uso de Managed Identities o Azure Key Vault para manejar credenciales de forma segura.\n",
    "- **Automatización:**  \n",
    "  - Azure Data Factory puede usarse para automatizar la ingesta de datos desde múltiples fuentes.\n",
    "- **Escalabilidad:**  \n",
    "  - Azure Blob Storage y ADLS están diseñados para manejar grandes volúmenes de datos sin comprometer el rendimiento.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure Data Factory Documentation](https://learn.microsoft.com/en-us/azure/data-factory/)\n",
    "- [Azure Key Vault Documentation](https://learn.microsoft.com/en-us/azure/key-vault/)\n",
    "\n",
    "#### **1.3. Ejemplo Práctico: Ingesta de Datos desde Azure Blob Storage**\n",
    "```python\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "\n",
    "# Conectar al Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(\"TU_CONNECTION_STRING\")\n",
    "blob_client = blob_service_client.get_blob_client(container=\"mi-contenedor\", blob=\"mi-archivo.csv\")\n",
    "\n",
    "# Descargar archivo\n",
    "with open(\"./datos/mi-archivo.csv\", \"wb\") as my_blob:\n",
    "    download_stream = blob_client.download_blob()\n",
    "    my_blob.write(download_stream.readall())\n",
    "\n",
    "# Cargar datos en un DataFrame\n",
    "datos = pd.read_csv(\"./datos/mi-archivo.csv\")\n",
    "print(datos.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Preprocesamiento y Transformación (1.5 horas)**\n",
    "\n",
    "#### **2.1. Conceptos Fundamentales**\n",
    "El preprocesamiento es crucial para preparar los datos antes del entrenamiento del modelo. Azure ML proporciona herramientas para realizar estas tareas de manera eficiente.\n",
    "\n",
    "- **Limpieza de Datos:**  \n",
    "  - Manejo de valores faltantes (`fillna`, `dropna`).\n",
    "  - Eliminación de duplicados y corrección de errores.\n",
    "\n",
    "- **Normalización y Escalado:**  \n",
    "  - Técnicas como `StandardScaler` (normalización Z-score) o `MinMaxScaler` (escalado entre 0 y 1).\n",
    "\n",
    "- **Ingeniería de Características:**  \n",
    "  - Creación de nuevas características mediante técnicas como PCA, one-hot encoding, o embeddings.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Scikit-learn Preprocessing Documentation](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "- [Azure ML Preprocessing Modules](https://learn.microsoft.com/en-us/azure/machine-learning/concept-preprocessing)\n",
    "\n",
    "#### **2.2. Opciones y Posibilidades**\n",
    "- **Módulos Predefinidos en Azure ML Designer:**  \n",
    "  - Herramientas visuales para limpieza y transformación de datos sin necesidad de escribir código.\n",
    "- **Scripts Personalizados:**  \n",
    "  - Uso de Python para implementar transformaciones personalizadas.\n",
    "- **Paralelización:**  \n",
    "  - Procesamiento distribuido en clústeres para grandes volúmenes de datos.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure ML Designer Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-designer)\n",
    "- [Distributed Computing in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)\n",
    "\n",
    "#### **2.3. Ejemplo Práctico: Limpieza y Normalización de Datos**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Datos de ejemplo\n",
    "datos = pd.DataFrame({\n",
    "    'edad': [25, 30, None, 35],\n",
    "    'ingreso': [50000, 60000, 70000, 80000]\n",
    "})\n",
    "\n",
    "# Limpieza: Rellenar valores faltantes\n",
    "datos['edad'].fillna(datos['edad'].mean(), inplace=True)\n",
    "\n",
    "# Normalización\n",
    "scaler = StandardScaler()\n",
    "datos_normalizados = scaler.fit_transform(datos)\n",
    "print(datos_normalizados)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Entrenamiento del Modelo (2 horas)**\n",
    "\n",
    "#### **3.1. Selección de Algoritmos**\n",
    "Azure ML soporta una amplia gama de algoritmos de machine learning, tanto tradicionales como avanzados.\n",
    "\n",
    "- **Regresión:**  \n",
    "  - Regresión lineal, regresión logística, árboles de decisión.\n",
    "- **Clasificación:**  \n",
    "  - Random Forest, SVM, Gradient Boosting.\n",
    "- **Clustering:**  \n",
    "  - K-Means, DBSCAN, clustering jerárquico.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Scikit-learn Algorithms Documentation](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- [Azure ML Algorithm Cheat Sheet](https://learn.microsoft.com/en-us/azure/machine-learning/algorithm-cheat-sheet)\n",
    "\n",
    "#### **3.2. AutoML**\n",
    "- Automatiza la selección de algoritmos, hiperparámetros y validación cruzada.\n",
    "- Genera informes detallados sobre el rendimiento de cada modelo.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure AutoML Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)\n",
    "\n",
    "#### **3.3. Compute Instances**\n",
    "- **Compute Targets:**  \n",
    "  - Máquinas virtuales dedicadas, clústeres de GPU, Kubernetes.\n",
    "- **Distribución:**  \n",
    "  - Entrenamiento distribuido para acelerar procesos intensivos.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure Compute Targets Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)\n",
    "\n",
    "#### **3.4. Ejemplo Práctico: Entrenamiento con AutoML**\n",
    "```python\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Configuración de AutoML\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    compute_target=\"mi-cluster\",\n",
    "    training_data=dataset,\n",
    "    label_column_name=\"etiqueta\",\n",
    "    iterations=10\n",
    ")\n",
    "\n",
    "# Ejecutar experimento\n",
    "experimento = Experiment(workspace=ws, name=\"mi-experimento-automl\")\n",
    "corrida = experimento.submit(automl_config)\n",
    "corrida.wait_for_completion(show_output=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evaluación del Modelo (1 hora)**\n",
    "\n",
    "#### **4.1. Métricas Clave**\n",
    "- **Clasificación:**  \n",
    "  - Precisión, recall, F1-score, matriz de confusión.\n",
    "- **Regresión:**  \n",
    "  - RMSE, MAE, R².\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Model Evaluation Metrics in Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [Azure ML Model Evaluation Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-track-experiments)\n",
    "\n",
    "#### **4.2. Validación Cruzada**\n",
    "- Divide los datos en k subconjuntos para evaluar la robustez del modelo.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Cross-Validation in Scikit-learn](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "#### **4.3. Ejemplo Práctico: Evaluación de un Modelo**\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Reporte de métricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Implementación en Pipelines (0.5 horas)**\n",
    "\n",
    "#### **5.1. Diseño de Pipelines Modulares**\n",
    "Azure ML Pipelines permite automatizar cada fase del ciclo de vida.\n",
    "\n",
    "- **Pasos Comunes:**  \n",
    "  - Ingesta, preprocesamiento, entrenamiento, evaluación.\n",
    "- **Reutilización:**  \n",
    "  - Pasos modulares que pueden reutilizarse en diferentes pipelines.\n",
    "\n",
    "#### **Referencias:**\n",
    "- [Azure ML Pipelines Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/concept-ml-pipelines)\n",
    "\n",
    "#### **5.2. Ejemplo Práctico: Pipeline Completo**\n",
    "```python\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Definir pasos\n",
    "paso_ingesta = PythonScriptStep(script_name=\"ingesta.py\", ...)\n",
    "paso_preprocesamiento = PythonScriptStep(script_name=\"preprocesamiento.py\", ...)\n",
    "paso_entrenamiento = PythonScriptStep(script_name=\"entrenamiento.py\", ...)\n",
    "paso_evaluacion = PythonScriptStep(script_name=\"evaluacion.py\", ...)\n",
    "\n",
    "# Crear pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[paso_ingesta, paso_preprocesamiento, paso_entrenamiento, paso_evaluacion])\n",
    "pipeline.validate()\n",
    "\n",
    "# Ejecutar pipeline\n",
    "experimento = Experiment(workspace=ws, name=\"mi-pipeline\")\n",
    "corrida = experimento.submit(pipeline)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Actividad Práctica (1 hora)**\n",
    "\n",
    "**Título:** Crear un pipeline que ingrese datos, realice preprocesamiento, entrene un modelo de clasificación y evalúe su rendimiento.\n",
    "\n",
    "#### **Pasos:**\n",
    "1. **Ingesta de Datos:**  \n",
    "   - Descargar un conjunto de datos desde Azure Blob Storage o una API RESTful.\n",
    "\n",
    "2. **Preprocesamiento:**  \n",
    "   - Limpiar los datos y realizar ingeniería de características.\n",
    "\n",
    "3. **Entrenamiento:**  \n",
    "   - Entrenar un modelo de clasificación utilizando Scikit-learn o AutoML.\n",
    "\n",
    "4. **Evaluación:**  \n",
    "   - Evaluar el modelo utilizando métricas clave como precisión y F1-score.\n",
    "\n",
    "5. **Pipeline:**  \n",
    "   - Diseñar un pipeline modular que automatice todas las etapas anteriores.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusión**\n",
    "Este módulo proporciona una visión completa del ciclo de vida de creación y entrenamiento de modelos dentro de pipelines. Al combinar teoría y práctica, los participantes estarán preparados para implementar soluciones de machine learning escalables y automatizadas en entornos reales.\n",
    "\n",
    "Si tienes más preguntas o necesitas profundizar en algún tema, no dudes en preguntar. ¡Espero que este curso sea útil!\n",
    "\n",
    "#### **Referencias Generales:**\n",
    "- [Azure Machine Learning Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/)\n",
    "- [Scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
